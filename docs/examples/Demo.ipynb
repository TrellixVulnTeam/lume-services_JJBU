{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0aeb04c",
   "metadata": {},
   "source": [
    "# LUME-services demo\n",
    "In this notebook, we will configure LUME-services to use the service configuration used to launch our docker-compose services. Make sure you've completed all steps outlined in https://slaclab.github.io/lume-services/demo/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b0cfe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)  # Lets check the logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cb7294",
   "metadata": {},
   "source": [
    "## Configure services\n",
    "LUME-services is packages with a configuration utility that reads environment variables and initializes services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1e88af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lume_services.config:Configuring LUME-services environment...\n",
      "INFO:lume_services.config:Environment configured.\n"
     ]
    }
   ],
   "source": [
    "from lume_services import config\n",
    "config.configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14910cc",
   "metadata": {},
   "source": [
    "## if you're running this many time, creation will fail because of uniqueness... You can reset since this is a dev server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1dae5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_db_service._reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4ba844",
   "metadata": {},
   "source": [
    "## Create a model\n",
    "The LUME-services Model provides an API to all model services and facilitates all model operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "299e5321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT model.model_id, model.created, model.author, model.laboratory, model.facility, model.beampath, model.description \n",
      "FROM model \n",
      "WHERE model.author = :author_1 AND model.laboratory = :laboratory_1 AND model.facility = :facility_1 AND model.beampath = :beampath_1 AND model.description = :description_1\n",
      "INFO:lume_services.services.models.db.db:ModelDB inserting: INSERT INTO model (author, laboratory, facility, beampath, description) VALUES (:author, :laboratory, :facility, :beampath, :description)\n",
      "INFO:lume_services.services.models.db.db:Sucessfully executed: INSERT INTO model (author, laboratory, facility, beampath, description) VALUES (:author, :laboratory, :facility, :beampath, :description)\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT model.model_id, model.created, model.author, model.laboratory, model.facility, model.beampath, model.description \n",
      "FROM model \n",
      "WHERE model.model_id = :model_id_1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(metadata=Model(                     model_id=1,                     created=datetime.datetime(2022, 10, 1, 6, 48, 27),                     author='Jackie Garrahan'),                     laboratory='slac',                     facility='lcls',                     beampath='cu_hxr',                     description='test_model'                 ), deployment=None, results=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lume_services.models import Model\n",
    "\n",
    "model = Model.create_model(\n",
    "    author = \"Jackie Garrahan\",\n",
    "    laboratory = \"slac\",\n",
    "    facility = \"lcls\",\n",
    "    beampath = \"cu_hxr\",\n",
    "    description = \"test_model\"\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3088ad03",
   "metadata": {},
   "source": [
    "## Create a project\n",
    "Workflows are organized by the Prefect scheduler into different projects. Below, we access the configured services directly (TODO create project registry utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7a075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_db_service = config.context.model_db_service()\n",
    "scheduling_service = config.context.scheduling_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3c31d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: The below cell will raise an error if run 2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcd2f83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lume_services.services.models.db.db:ModelDB inserting: INSERT INTO project (project_name, description) VALUES (:project_name, :description)\n",
      "INFO:lume_services.services.models.db.db:Sucessfully executed: INSERT INTO project (project_name, description) VALUES (:project_name, :description)\n"
     ]
    }
   ],
   "source": [
    "# create a project\n",
    "project_name = model_db_service.store_project(\n",
    "    project_name=\"test\", description=\"my_description\"\n",
    ")\n",
    "scheduling_service.create_project(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abbe01a",
   "metadata": {},
   "source": [
    "You can now find this project in you Prefect UI at http://localhost:8080\n",
    "\n",
    "\n",
    "![project](https://slaclab.github.io/lume-services/files/project_nav.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc23acff",
   "metadata": {},
   "source": [
    "## Create a deployment for your model\n",
    "Replace `source_path` with the path to your release tarball below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2346c829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lume_services.models.model:installing package\n",
      "INFO:lume_services.environment.solver:https://github.com/jacquelinegarrahan/my-model/releases/download/v0.0.44/my_model-0.0.44.tar.gz saved to /var/folders/nh/g2v_nmtj7t1g94gmjtgjrk3r0000gn/T/tmp4c5jbhpr/my_model-0.0.44.tar.gz\n",
      "INFO:lume_services.environment.solver:Version 0.0.44 of my_model already installed.\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT deployment.sha256, deployment.deployment_id, deployment.version, deployment.deploy_date, deployment.package_import_name, deployment.asset_dir, deployment.source, deployment.image, deployment.is_live, deployment.model_id \n",
      "FROM deployment \n",
      "WHERE deployment.model_id = :model_id_1 AND deployment.version = :version_1\n",
      "INFO:lume_services.services.models.db.db:ModelDB inserting: INSERT INTO deployment (version, package_import_name, asset_dir, source, sha256, image, is_live, model_id) VALUES (:version, :package_import_name, :asset_dir, :source, :sha256, :image, :is_live, :model_id)\n",
      "INFO:lume_services.services.models.db.db:Sucessfully executed: INSERT INTO deployment (version, package_import_name, asset_dir, source, sha256, image, is_live, model_id) VALUES (:version, :package_import_name, :asset_dir, :source, :sha256, :image, :is_live, :model_id)\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT flow.flow_id, flow.flow_name, flow.project_name, flow.deployment_id \n",
      "FROM flow \n",
      "WHERE flow.deployment_id = :deployment_id_1\n",
      "INFO:lume_services.services.scheduling.backends.server:Flow run config is not empty. Clearing existing labels and assigning                     new.\n",
      "/Users/jacquelinegarrahan/miniconda3/envs/my-model-dev/lib/python3.10/site-packages/prefect/core/flow.py:1726: UserWarning: No result handler was specified on your Flow. Cloud features such as input caching and resuming task runs from failure may not work properly.\n",
      "  registered_flow = client.register(\n",
      "INFO:lume_services.services.models.db.db:ModelDB inserting: INSERT INTO flow (flow_id, flow_name, project_name, deployment_id) VALUES (:flow_id, :flow_name, :project_name, :deployment_id)\n",
      "INFO:lume_services.services.models.db.db:Sucessfully executed: INSERT INTO flow (flow_id, flow_name, project_name, deployment_id) VALUES (:flow_id, :flow_name, :project_name, :deployment_id)\n",
      "INFO:lume_services.models.model:Loading deployment 1\n",
      "INFO:lume_services.models.model:Loading deployment 1\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT deployment.sha256, deployment.deployment_id, deployment.version, deployment.deploy_date, deployment.package_import_name, deployment.asset_dir, deployment.source, deployment.image, deployment.is_live, deployment.model_id \n",
      "FROM deployment \n",
      "WHERE deployment.model_id = :model_id_1 AND deployment.deployment_id = :deployment_id_1\n",
      "INFO:lume_services.models.model:Deployment loaded.\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT flow.flow_id, flow.flow_name, flow.project_name, flow.deployment_id \n",
      "FROM flow \n",
      "WHERE flow.deployment_id = :deployment_id_1\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT project.project_name, project.description \n",
      "FROM project \n",
      "WHERE project.project_name = :project_name_1\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT flow_of_flows._id, flow_of_flows.parent_flow_id, flow_of_flows.flow_id, flow_of_flows.position \n",
      "FROM flow_of_flows \n",
      "WHERE flow_of_flows.parent_flow_id = :parent_flow_id_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow URL: http://localhost:8080/default/flow/c13c5222-b967-404c-bf41-5ff5c1f0f38e\n",
      " └── ID: 8352b84e-ae5f-4e86-9143-921b0eb6d37d\n",
      " └── Project: test\n",
      " └── Labels: ['lume-services']\n"
     ]
    }
   ],
   "source": [
    "source_path = \"https://github.com/jacquelinegarrahan/my-model/releases/download/v0.0.44/my_model-0.0.44.tar.gz\"\n",
    "# populates local channel\n",
    "model.store_deployment(source_path, project_name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f0c1c",
   "metadata": {},
   "source": [
    "## Run the Prefect workflow directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "514e0aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:28-0700] INFO - prefect.FlowRunner | Beginning Flow run for 'my-model'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.FlowRunner:Beginning Flow run for 'my-model'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:28-0700] INFO - prefect.TaskRunner | Task 'configure_lume_services': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'configure_lume_services': Starting task run...\n",
      "INFO:lume_services.config:Configuring LUME-services environment...\n",
      "INFO:lume_services.config:Environment configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'configure_lume_services': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'configure_lume_services': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'filename': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'filename': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'filename': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'filename': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'check_local_execution': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'check_local_execution': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'check_local_execution': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'check_local_execution': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'input1': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'input1': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'input1': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'input1': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'input2': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'input2': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'input2': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'input2': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'filesystem_identifier': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'filesystem_identifier': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'filesystem_identifier': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'filesystem_identifier': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'case(False)': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'case(False)': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'case(False)': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'case(False)': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'List': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'List': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'List': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'List': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'Dict': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'Dict': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'Dict': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'Dict': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'prepare_lume_model_variables': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'prepare_lume_model_variables': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'prepare_lume_model_variables': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'prepare_lume_model_variables': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'evaluate': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'evaluate': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'evaluate': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'evaluate': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'format_file': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'format_file': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'format_file': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'format_file': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'save_file': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'save_file': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'save_file': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'save_file': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'format_result': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'format_result': Starting task run...\n",
      "WARNING:lume_services.results.generic:No project_name passed to result\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'format_result': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'format_result': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'save_db_result': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'save_db_result': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.TaskRunner | Task 'save_db_result': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'save_db_result': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-30 23:48:29-0700] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.FlowRunner:Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    }
   ],
   "source": [
    "flow_run = model.deployment.flow.prefect_flow.run(**{\n",
    "                        \"input1\": 1, \n",
    "                        \"input2\": 2, \n",
    "                        \"filename\": \"test_file.txt\", \n",
    "                        \"filesystem_identifier\":\"local\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc08d87",
   "metadata": {},
   "source": [
    "## Run the workflow inside the service cluster\n",
    "We can use the model interface to directly deploy workflows. When sourcing our environment (`docs/examples/demo.env`), we defined a mount point for the file system using the alias `/lume-services/data`. Let's kick off this workflow and save the file output to that directory. \n",
    "After running the next cell, you'll be able to see the running container in your docker desktop and examine the flow using the Prefect UI at http://localhost:8080/default?flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90a5769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(\n",
    "    parameters={\n",
    "        \"input1\": 1, \n",
    "        \"input2\": 2, \n",
    "        \"filename\": \"/lume-services/data/test_file.txt\", \n",
    "        \"filesystem_identifier\":\"mounted\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ca124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.deployment.flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409851f9",
   "metadata": {},
   "source": [
    "# Get results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ffa8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.get_results()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b388faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = model.get_results_df()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f26a31",
   "metadata": {},
   "source": [
    "## Load model using model id\n",
    "Once your model has been registered, you can use the `Model` api object to interact with your model without running the above registration steps. Let's load a new model object using the model_id we registered above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload \n",
    "import lume_services\n",
    "reload(lume_services.models)\n",
    "from lume_services.models import Model\n",
    "\n",
    "model_id = model.metadata.model_id\n",
    "loaded_model = Model(model_id=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a15668",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ca3ce4",
   "metadata": {},
   "source": [
    "## Load existing model object\n",
    "Loading a model using the load_deployment method without passing a deployment_id will load the latest deployment registered for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040bb4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.load_deployment()\n",
    "loaded_model.deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ff1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = loaded_model.run_and_return(\n",
    "    collection=\"test\",\n",
    "    parameters={\n",
    "                    \"input1\": 1.0, \n",
    "                    \"input2\": 2.0, \n",
    "                    \"filename\": \"/lume-services/data/test_file.txt\", \n",
    "                    \"filesystem_identifier\":\"local\"\n",
    "    },\n",
    "    task_name=\"save_db_result\" # Want to get the result from the save_db_result task\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c25a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f09607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b1aa5d32c5360a08f3d071b8537e8759b8901de3eea112666c46651e79793b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
